{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import The nessary library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Read The Data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/questions.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>scheme</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stand Up India buissness</td>\n",
       "      <td>business loan for backward</td>\n",
       "      <td>Nature</td>\n",
       "      <td>The objective of the Stand-Up India scheme is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stand Up India buissness</td>\n",
       "      <td>business loan for backward</td>\n",
       "      <td>Purpose</td>\n",
       "      <td>The objective of the Stand-Up India scheme is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Stand Up India buissness</td>\n",
       "      <td>business loan for backward</td>\n",
       "      <td>Objective</td>\n",
       "      <td>The objective of the Stand-Up India scheme is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Stand Up India buissness</td>\n",
       "      <td>business loan for backward</td>\n",
       "      <td>Introduction of the scheme</td>\n",
       "      <td>The objective of the Stand-Up India scheme is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Stand Up India buissness</td>\n",
       "      <td>business loan for backward</td>\n",
       "      <td>Quantum of loan</td>\n",
       "      <td>The loans provided under this scheme will rang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                    scheme                    category  \\\n",
       "0        0  Stand Up India buissness  business loan for backward   \n",
       "1        1  Stand Up India buissness  business loan for backward   \n",
       "2        2  Stand Up India buissness  business loan for backward   \n",
       "3        3  Stand Up India buissness  business loan for backward   \n",
       "4        4  Stand Up India buissness  business loan for backward   \n",
       "\n",
       "                        title  \\\n",
       "0                      Nature   \n",
       "1                     Purpose   \n",
       "2                   Objective   \n",
       "3  Introduction of the scheme   \n",
       "4             Quantum of loan   \n",
       "\n",
       "                                              answer  \n",
       "0  The objective of the Stand-Up India scheme is ...  \n",
       "1  The objective of the Stand-Up India scheme is ...  \n",
       "2  The objective of the Stand-Up India scheme is ...  \n",
       "3  The objective of the Stand-Up India scheme is ...  \n",
       "4  The loans provided under this scheme will rang...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Information about data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_id', 'scheme', 'category', 'title', 'answer'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_id     0\n",
       "scheme      0\n",
       "category    0\n",
       "title       0\n",
       "answer      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check a   null value\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill a  null value\n",
    "df.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_id     0\n",
       "scheme      0\n",
       "category    0\n",
       "title       0\n",
       "answer      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after filling checking null value check\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_id      int64\n",
       "scheme      object\n",
       "category    object\n",
       "title       object\n",
       "answer      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data types of columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scheme\n",
       "Pradhan Mantri Suraksh Bima Yojna                        23\n",
       "Pradhan Mantri Awas Yojana                               20\n",
       "Atal Pension Yojana                                      19\n",
       "Pradhan Mantri Fasal Bima Yojana                         19\n",
       "vida lakshmi yojana                                      19\n",
       "general Insurance                                        18\n",
       "Rashtriya Swasthya Bima Yojana                           17\n",
       "Aam admi bima yojana                                     16\n",
       "Scheme For Liberation and Rehabilitation of Scavenger    16\n",
       "Pradhan Mantri Jeevan Jyoti BIMA Yojana                  16\n",
       "Pradhan Mantri Vaya Vandana Yojana                       15\n",
       "Varishtha Pension bima yojana                            15\n",
       "Prime Ministers Rozgar Yojana                            14\n",
       "Pradhan Mantri Mudra Yojana                              13\n",
       "Employment State Insurance Scheme                        13\n",
       "National Social Assistance Programme insurance           13\n",
       "Stand Up India buissness                                 13\n",
       "Pradhan Mantri Jan-Dhan Yojana                           12\n",
       "pradhan mantri jan arogya                                11\n",
       "National Pension System                                  11\n",
       "genaral home loan                                        10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scheme'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "health insurance                      41\n",
       "Health insurance                      23\n",
       "Home loan                             20\n",
       "pension scheme                        19\n",
       "agriculture crop insurance            19\n",
       "education loan                        19\n",
       "general insurance faq                 18\n",
       "accident disablity death insurance    16\n",
       "house loan                            16\n",
       "life insurance                        16\n",
       "pension scheme insurance              15\n",
       "pension insurance                     15\n",
       "buissness loan                        14\n",
       "small business loan                   13\n",
       "insurance                             13\n",
       "business loan for backward            13\n",
       "accidental and death insurance        12\n",
       "senior citizen insurance              11\n",
       "genaral home loan faq                 10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Introduction of the scheme                             12\n",
       "Eligibility Criteria                                   11\n",
       "Objective                                              10\n",
       "Nature                                                  9\n",
       "Purpose                                                 9\n",
       "                                                       ..\n",
       "What is the nature of Pradhan Mantri Awas Yojana ?      1\n",
       "What is the purpose of Pradhan Mantri Awas Yojana ?     1\n",
       "What are the programs this scheme addresses ?           1\n",
       "Who is eligible for this scheme ?                       1\n",
       "Expenses Considered for Loan                            1\n",
       "Name: count, Length: 239, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\0630\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "C:\\Users\\0630\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your CSV dataset\n",
    "data = df\n",
    "user_messages = data[\"title\"]\n",
    "chatbot_responses = data[\"answer\"]\n",
    "\n",
    "# Initialize the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize and encode your dataset\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for i in range(len(user_messages)):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        user_messages[i],\n",
    "        chatbot_responses[i],\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids.append(encoded_dict[\"input_ids\"])\n",
    "    attention_masks.append(encoded_dict[\"attention_mask\"])\n",
    "\n",
    "# Convert lists to tensors\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor([1] * len(data))  # Assuming positive examples\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_inputs, val_inputs, train_masks, val_masks, train_labels, val_labels = train_test_split(\n",
    "    input_ids, attention_masks, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()  # Assuming binary classification\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"your_chatbot_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"your_chatbot_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "input_text = [\"bhima yojana\"]\n",
    "\n",
    "# Tokenize and encode the input text\n",
    "input_ids = tokenizer.encode(input_text, add_special_tokens=True, max_length=128, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "attention_mask = input_ids.ne(0)  # Create attention mask (1 for tokens, 0 for padding)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# If you're performing binary classification, you can convert the logits to probabilities:\n",
    "probabilities = torch.sigmoid(logits)\n",
    "\n",
    "# Depending on your specific use case, you can now interpret the model's output for your chatbot application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2200, 0.8394]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"your_chatbot_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import json\n",
    "\n",
    "# Load the configuration from the JSON file\n",
    "with open('your_chatbot_model/config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(config[\"_name_or_path\"])\n",
    "\n",
    "# # # Create a BERT model using the configuration\n",
    "# model = BertForSequenceClassification.from_pretrained(config[\"_name_or_path\"], config=config)\n",
    "\n",
    "# Now you can use the `tokenizer` to tokenize text and the `model` for various NLP tasks, such as chatbot responses or text classification.\n",
    "\n",
    "# Example of using the tokenizer and model\n",
    "text = \"Personal Loan\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.4742,  1.8961]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: The objective of the Stand-Up India scheme is to facilitate bank loans between 10 lakh and 1 Crore to at least one Scheduled Caste (SC) or Scheduled Tribe (ST) borrower and at least one woman borrower per bank branch for setting up a greenfield enterprise. This enterprise may be in manufacturing, services or the trading sector. In case of non-individual enterprises at least 51% of the shareholding and controlling stake should be held by either an SC/ST or Woman entrepreneur.\n"
     ]
    }
   ],
   "source": [
    "logits = outputs.logits  # Get the classification scores\n",
    "predicted_label_id = logits.argmax().item()  # Get the predicted label ID\n",
    "class_names = df['answer']  # Replace with your class names\n",
    "predicted_label = class_names[predicted_label_id]\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_id', 'scheme', 'category', 'title', 'answer'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data[df['title'].str.contains(text, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "inp = 'What would be the premium payable'\n",
    "fil_data = data[data['title'].str.contains(inp, case=False)]\n",
    "if fil_data.empty:\n",
    "    print(\"Not Responce\")\n",
    "else:\n",
    "    text = fil_data.sort_values(by='title')[:1]\n",
    "    Ans = text['answer'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Premium payable is Rs.12/- per annum per member.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                Nature\n",
       "1                                               Purpose\n",
       "2                                             Objective\n",
       "3                            Introduction of the scheme\n",
       "4                                       Quantum of loan\n",
       "                            ...                        \n",
       "95    Can those families whose names are not on the ...\n",
       "96        What would be the benefits under the scheme ?\n",
       "97                  What would be the premium payable ?\n",
       "98                       How will the premium be paid ?\n",
       "99            Who will offer or administer the scheme ?\n",
       "Name: title, Length: 100, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = 'purpose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purpose\n",
      "Purpose\n",
      "Purpose\n",
      "Purpose\n",
      "What is the purpose of MUDRA?\n",
      "What is the purpose of scheme ?\n",
      "What is the nature or purpose of the scheme ?\n",
      "What is the purpose of Pradhan Mantri Awas Yojana ?\n",
      "What is the purpose of the scheme\n",
      "Purpose\n",
      "Purpose\n",
      "Purpose\n",
      "Purpose\n",
      "what is the purpose of the scheme\n",
      "What is the purpose of the scheme\n",
      "What is the purpose of the scheme\n",
      "Purpose\n",
      "What is the purpose of the scheme\n"
     ]
    }
   ],
   "source": [
    "# Define a function to generate related text\n",
    "def generate_related_text(input_text, dataset):\n",
    "    related_texts = []\n",
    "    for text in dataset:\n",
    "        if re.search(input_text, text, re.IGNORECASE):\n",
    "            related_texts.append(text)\n",
    "    return related_texts\n",
    "\n",
    "# Generate related text for the input\n",
    "related_text = generate_related_text(inp, df['title'])\n",
    "\n",
    "# Print the related text\n",
    "for text in related_text:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_id', 'scheme', 'category', 'title', 'answer'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Response logits: hello can you please tell your name\n",
      "hello rr\n",
      "wich bank information yoy want\n",
      "1) RBI\n",
      "2) NABARD\n",
      "enter wich scheme information you want\n",
      "scheme\n",
      "Pradhan Mantri Suraksh Bima Yojna                        23\n",
      "Pradhan Mantri Awas Yojana                               20\n",
      "Atal Pension Yojana                                      19\n",
      "Pradhan Mantri Fasal Bima Yojana                         19\n",
      "vida lakshmi yojana                                      19\n",
      "general Insurance                                        18\n",
      "Rashtriya Swasthya Bima Yojana                           17\n",
      "Aam admi bima yojana                                     16\n",
      "Scheme For Liberation and Rehabilitation of Scavenger    16\n",
      "Pradhan Mantri Jeevan Jyoti BIMA Yojana                  16\n",
      "Pradhan Mantri Vaya Vandana Yojana                       15\n",
      "Varishtha Pension bima yojana                            15\n",
      "Prime Ministers Rozgar Yojana                            14\n",
      "Pradhan Mantri Mudra Yojana                              13\n",
      "Employment State Insurance Scheme                        13\n",
      "National Social Assistance Programme insurance           13\n",
      "Stand Up India buissness                                 13\n",
      "Pradhan Mantri Jan-Dhan Yojana                           12\n",
      "pradhan mantri jan arogya                                11\n",
      "National Pension System                                  11\n",
      "genaral home loan                                        10\n",
      "Name: count, dtype: int64\n",
      "Chatbot: Response logits:      post_id                                   scheme        category  \\\n",
      "261      261  Pradhan Mantri Jeevan Jyoti BIMA Yojana  life insurance   \n",
      "\n",
      "                                                 title  \\\n",
      "261  What is PRADHAN MANTRI JEEVAN JYOTI BIMA YOJAN...   \n",
      "\n",
      "                                                answer  \n",
      "261  The scheme is a one year cover Term Life Insur...  \n",
      "Chatbot: Response logits:      post_id                                   scheme        category  \\\n",
      "261      261  Pradhan Mantri Jeevan Jyoti BIMA Yojana  life insurance   \n",
      "\n",
      "                                                 title  \\\n",
      "261  What is PRADHAN MANTRI JEEVAN JYOTI BIMA YOJAN...   \n",
      "\n",
      "                                                answer  \n",
      "261  The scheme is a one year cover Term Life Insur...  \n",
      "Chatbot: Response logits:    post_id                    scheme                    category  \\\n",
      "9        9  Stand Up India buissness  business loan for backward   \n",
      "\n",
      "                                               title  \\\n",
      "9  Difference between  Stand-Up India Scheme and ...   \n",
      "\n",
      "                                              answer  \n",
      "9  SMILE Scheme is operated only through SIDBI fo...  \n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"You: \")\n",
    "if user_input == 'hi' or 'hello':\n",
    "    result = 'hello can you please tell your name'\n",
    "    print(\"Chatbot: Response logits:\", result)\n",
    "    user_input = input(\"You: \")\n",
    "    print(\"hello\", user_input)\n",
    "    print('wich bank information yoy want')\n",
    "    print('1) RBI')\n",
    "    print('2) NABARD')\n",
    "    user_input = input(\"You: \")\n",
    "if user_input == 'RBI' or 'rbi':\n",
    "    print(\"enter wich scheme information you want\")\n",
    "    print(df['scheme'].value_counts())\n",
    "    # Load the configuration from the JSON file\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        with open('your_chatbot_model/config.json', 'r') as file:\n",
    "            config = json.load(file)\n",
    "        result = data[df['title'].str.contains(user_input, case=False)][:1]\n",
    "        print(\"Chatbot: Response logits:\", result)\n",
    "\n",
    "# You can post-process the response logits to generate human-readable responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
